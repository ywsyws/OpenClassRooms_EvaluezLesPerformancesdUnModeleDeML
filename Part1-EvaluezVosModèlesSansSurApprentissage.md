## 1. Comprenez ce qui fait un bon modèle d'apprentissage
### Généralisation
Un **bon modèle de machine learning**, c’est un modèle qui généralise.

### Sur-apprentissage et compromis biais-variance
Un modèle qui **sur-apprend** est un modèle qui est **trop complexe** par rapport à la réalité qu’il essaie de représenter. Nous avons tendance à préférer des modèles simples ; c’est le principe du **rasoir d’Ockham** (ou Occam), selon lequel les hypothèses suffisantes les plus simples sont les plus vraisemblables. Par ailleurs, coller de trop près aux données est une mauvaise idée car elles sont inévitablement bruitées :
- Par des erreurs de mesure (les appareils que nous utilisons pour mesurer les variables qui représentent nos données peuvent faire des erreurs techniques) ;
- Par des erreurs d’étiquetage (l’erreur est humaine, et il se peut que certaines des étiquettes ne soient pas les bonnes) ;
- Parce que nous n’avons pas mesuré les variables les plus pertinentes, soit parce qu'on ne les connaît pas, soit parce qu'elles sont très compliquées à mesurer

"Sous-apprentissage" - Les modèles **trop simples**



### Les problèmes mal posés

### Ressources informatiques

### En résumé